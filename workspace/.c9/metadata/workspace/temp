{"filter":false,"title":"temp","tooltip":"/temp","undoManager":{"mark":0,"position":0,"stack":[[{"group":"doc","deltas":[{"start":{"row":0,"column":0},"end":{"row":36,"column":6},"action":"insert","lines":["","    def store_data_util(self, url, depth):","        ","        # print 'Current url: ' + url","        if url[0:8] == 'https://':","            return []","            ","        base = self.get_base(url)","        base_domain = self.get_base_domain(url)","        data = self.get_data(url)","        self.database.store({'url': url, 'data': data['info']})","        if depth > 5:","            return data['links']","        else:","            for link in data['links']:","                if type(link)!=str or link[0:1] == '#' or link[0:8] == 'https://' or self.crawledUrls.has_key(url.lower()) or link.rfind('javascript:void(0)')!=-1:","                    continue","                link = link.strip()","                ","                if len(link)!=0:","                    if(link[0]=='/'):","                        link = base_domain + link","                    elif (link[0:7] != 'http://'):","                        link = base + link","                ","                try:","                    links = self.store_data(link, depth+1, url)","                except urllib.HTTPError, e:","                    print 'HTTP Error at link: ' + link","                except urllib.URLError, e:","                    print 'URL error for link \"' + link + '\"'","","            self.crawledUrls[url.lower()] = True","            self.urlDb.store(url.lower() + \"\\n\")","            ","            return data['links']","    */"]}]}]]},"ace":{"folds":[],"scrolltop":137.77778142764254,"scrollleft":0,"selection":{"start":{"row":30,"column":61},"end":{"row":30,"column":61},"isBackwards":false},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":0},"timestamp":1427994024000,"hash":"9ae835fa0ace2edb9d0ebdbf60fd9376ad367105"}